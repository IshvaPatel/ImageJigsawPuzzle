{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rp5Y-Ej6Cqt9",
        "outputId": "a2eeab3d-436f-45eb-c978-af6977d7dc9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting efficientnet_pytorch\n",
            "  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from efficientnet_pytorch) (2.1.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->efficientnet_pytorch) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->efficientnet_pytorch) (1.3.0)\n",
            "Building wheels for collected packages: efficientnet_pytorch\n",
            "  Building wheel for efficientnet_pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for efficientnet_pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16428 sha256=0aeb522e37d46d7c57b4fc93c008003be70aef5ed75d817d9fda3613c8514069\n",
            "  Stored in directory: /root/.cache/pip/wheels/03/3f/e9/911b1bc46869644912bda90a56bcf7b960f20b5187feea3baf\n",
            "Successfully built efficientnet_pytorch\n",
            "Installing collected packages: efficientnet_pytorch\n",
            "Successfully installed efficientnet_pytorch-0.7.1\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import CIFAR10\n",
        "!pip install efficientnet_pytorch\n",
        "from efficientnet_pytorch import EfficientNet\n",
        "import numpy as np\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To create an image jigsaw solver I first made functions to divide the image into 9 patches ,resize and shuffle them according to the permutations with the number of permutations being 64. And then I used the Cifar10 Dataset for the images and divided into ordered images and shuffeled images by using these functions"
      ],
      "metadata": {
        "id": "H_Pxala8jSZL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def shuffle_patches(image, permutation):\n",
        "    patches = np.split(image, 9)  # Assuming 3x3 patches\n",
        "    shuffled_patches = [patches[i] for i in permutation]\n",
        "    shuffled_image = np.concatenate(shuffled_patches)\n",
        "    return shuffled_image\n",
        "\n",
        "def generate_training_pairs(images):\n",
        "    pairs = []\n",
        "    for image in images:\n",
        "        # Divide the image into 3x3 patches\n",
        "        patches = []\n",
        "        for i in range(0, image.shape[0], image.shape[0] // 3):\n",
        "            for j in range(0, image.shape[1], image.shape[1] // 3):\n",
        "                patch = image[i:i + image.shape[0] // 3, j:j + image.shape[1] // 3]\n",
        "                patch = cv2.resize(patch, (224, 224))\n",
        "                patches.append(patch)\n",
        "        patches = np.array(patches)\n",
        "        shuffled_image = np.random.permutation(patches)\n",
        "        # Create training pair (shuffled, ordered)\n",
        "        pairs.append((shuffled_image, patches))\n",
        "    return pairs"
      ],
      "metadata": {
        "id": "-aQ0_aw9hT7v"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The ImageJigsawDataset takes the cifar datset and coverts it into pairs of ordered and shuffled images for the network to train and identify."
      ],
      "metadata": {
        "id": "hG3Cj4YhkOgk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom Dataset class for the image jigsaw puzzle task with transformations\n",
        "class ImageJigsawDataset(Dataset):\n",
        "    def __init__(self, cifar_dataset, transform=None):\n",
        "        self.cifar_dataset = cifar_dataset\n",
        "        self.transform = transform\n",
        "    def __len__(self):\n",
        "        return len(self.cifar_dataset)\n",
        "    def __getitem__(self, idx):\n",
        "        img, _ = self.cifar_dataset[idx]\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        pairs = generate_training_pairs([np.array(img)])\n",
        "\n",
        "        return pairs\n"
      ],
      "metadata": {
        "id": "p_0LBEPBhggi"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then I created a context free network using the efficientnet model to train on the ordered and shuffled pairs and added the convolutional layers for more effecient feature extraction as well as reducing the dimensions so that the fully connected layer can be managed easily."
      ],
      "metadata": {
        "id": "gJQHqxkLkeCG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Context-Free Network (CFN) Model\n",
        "class CFN(nn.Module):\n",
        "    def __init__(self, num_permutations, efficientnet_model):\n",
        "        super(CFN, self).__init__()\n",
        "        self.efficientnet_model = efficientnet_model\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        self.fc = nn.Linear(256 * 9, num_permutations)  # Assuming 3x3 patches\n",
        "\n",
        "    def forward(self, input1, input2):\n",
        "        output1 = self.efficientnet_model(input1)\n",
        "        output2 = self.efficientnet_model(input2)\n",
        "        output1 = self.conv(output1)\n",
        "        output2 = self.conv(output2)\n",
        "        output1 = output1.view(output1.size()[0], -1)\n",
        "        output2 = output2.view(output2.size()[0], -1)\n",
        "        output = torch.abs(output1 - output2)\n",
        "        output = self.fc(output)\n",
        "        return output"
      ],
      "metadata": {
        "id": "XbrFKVKqhhfZ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here I have loaded the efficientnet model ad cifar dataset and have applied ImageJigsawDataset on the loaded data so that it can be traied using the model."
      ],
      "metadata": {
        "id": "PheSNoiMlZXO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the EfficientNet model\n",
        "efficientnet_model = EfficientNet.from_pretrained('efficientnet-b0', num_classes=10)\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # Adjust as needed\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),  # Adjust normalization parameters\n",
        "])\n",
        "\n",
        "# Create CIFAR-10 dataset for image jigsaw puzzle\n",
        "cifar_dataset = CIFAR10(root=\"./data\", train=True, download=True, transform=None)\n",
        "jigsaw_dataset = ImageJigsawDataset(cifar_dataset, transform=transform)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tqSp5o1fhwqm",
        "outputId": "064d85fe-d0b4-441b-90b2-1eddca7da5ed"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b0-355c32eb.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet-b0-355c32eb.pth\n",
            "100%|██████████| 20.4M/20.4M [00:00<00:00, 48.1MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded pretrained weights for efficientnet-b0\n",
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:02<00:00, 57233903.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then I divided the data into train, pretrain and test data as specified"
      ],
      "metadata": {
        "id": "BaeHfYfflqhc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_size = len(jigsaw_dataset)\n",
        "train_size = int(0.05 * dataset_size)\n",
        "pretrain_size = int(0.45 * dataset_size)\n",
        "test_size = dataset_size - train_size - pretrain_size\n",
        "train_dataset, pretrain_dataset, test_dataset = random_split(jigsaw_dataset, [train_size, pretrain_size, test_size])\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "pretrain_loader = DataLoader(pretrain_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "hFWUZJHYhymY"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I then defined the optimizers and loss criteria and made finctions to pretrain and fine tune the data"
      ],
      "metadata": {
        "id": "v97fEdxQlyJX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = CFN(num_permutations=64, efficientnet_model=efficientnet_model)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "def pretrain_cfn_model(model, pretrain_loader, criterion, optimizer, epochs=5):\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss = 0.0\n",
        "\n",
        "        for batch in pretrain_loader:\n",
        "            pairs = batch[0]\n",
        "\n",
        "            input1 = torch.stack([pair[0] for pair in pairs])\n",
        "            input2 = torch.stack([pair[1] for pair in pairs])\n",
        "            target = torch.arange(len(pairs))\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(input1, input2)\n",
        "            loss = criterion(outputs, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        print(f\"Pretrain Epoch {epoch + 1}/{epochs}, Loss: {total_loss / len(pretrain_loader)}\")\n",
        "\n",
        "def finetune_cfn_model(model, train_loader, criterion, optimizer, epochs=5):\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss = 0.0\n",
        "\n",
        "        for batch in train_loader:\n",
        "            pairs = batch[0]\n",
        "\n",
        "            input1 = torch.stack([pair[0] for pair in pairs])\n",
        "            input2 = torch.stack([pair[1] for pair in pairs])\n",
        "            target = torch.arange(len(pairs))\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(input1, input2)\n",
        "            loss = criterion(outputs, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        print(f\"Fine-tune Epoch {epoch + 1}/{epochs}, Loss: {total_loss / len(train_loader)}\")"
      ],
      "metadata": {
        "id": "qzOyBSlEiA0u"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pretrain_cfn_model(model, pretrain_loader, criterion, optimizer, epochs=5)\n",
        "finetune_cfn_model(model, train_loader, criterion, optimizer, epochs=5)\n",
        "\n",
        "def evaluate_model(model, test_loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            pairs = batch[0]\n",
        "\n",
        "            input1 = torch.stack([pair[0] for pair in pairs])\n",
        "            input2 = torch.stack([pair[1] for pair in pairs])\n",
        "            target = torch.arange(len(pairs))\n",
        "\n",
        "            outputs = model(input1, input2)\n",
        "            predicted = torch.argmax(outputs, dim=1)\n",
        "            total += len(target)\n",
        "            correct += (predicted == target).sum().item()\n",
        "\n",
        "    accuracy = correct / total\n",
        "    print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "\n",
        "evaluate_model(model, test_loader)"
      ],
      "metadata": {
        "id": "RtC-7iYPiFnh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FEGCrL7BjC0l"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}